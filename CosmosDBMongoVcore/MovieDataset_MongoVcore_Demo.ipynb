{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55bd4e39",
   "metadata": {},
   "source": [
    "# ⚙️ Configuration Setup\n",
    "\n",
    "Before running this notebook, ensure you have:\n",
    "\n",
    "1. **Created a `.env` file** in the project root directory\n",
    "2. **Copied from `.env.example`** and filled in your actual credentials\n",
    "3. **Verified your `.gitignore`** includes `.env` to protect your secrets\n",
    "\n",
    "## Quick Setup Commands\n",
    "\n",
    "```bash\n",
    "# Copy the example file\n",
    "cp .env.example .env\n",
    "\n",
    "# Edit with your actual credentials\n",
    "# (Use your preferred text editor)\n",
    "```\n",
    "\n",
    "**🔐 Security Best Practices:**\n",
    "- Never commit `.env` files to version control\n",
    "- Use different `.env` files for different environments (dev, staging, prod)\n",
    "- Rotate your API keys regularly\n",
    "- Consider using Azure Key Vault for production deployments\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ea2e3f",
   "metadata": {},
   "source": [
    "# Movies Dataset Vector Database Demo with Azure Cosmos DB for MongoDB vCore\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Load the movies dataset into Azure Cosmos DB for MongoDB vCore\n",
    "2. Create collections with vector search capabilities using MongoDB's native vector indexing\n",
    "3. Use MongoDB vCore as a vector database for similarity search with $vectorSearch aggregation\n",
    "4. Demonstrate RAG (Retrieval Augmented Generation) patterns using MongoDB aggregation pipelines\n",
    "\n",
    "## Prerequisites\n",
    "- Azure Cosmos DB for MongoDB vCore account with vector search enabled\n",
    "- Movies dataset files in the data/moviesdataset folder\n",
    "- Required Python packages: pandas, pymongo, motor, numpy, openai, python-dotenv\n",
    "- **Environment Configuration**: Create a `.env` file in the project root with the following variables:\n",
    "  ```\n",
    "  # Azure OpenAI Configuration\n",
    "  AZURE_OPENAI_ENDPOINT=your_azure_openai_endpoint\n",
    "  AZURE_OPENAI_API_KEY=your_azure_openai_api_key\n",
    "  AZURE_OPENAI_API_VERSION=2024-06-01\n",
    "  EMBEDDING_MODEL=text-embedding-ada-002\n",
    "  GENERATION_MODEL=gpt-4o\n",
    "\n",
    "  # Azure Cosmos DB for MongoDB vCore Configuration\n",
    "  MONGODB_CONNECTION_STRING=mongodb+srv://username:password@cluster.mongocluster.cosmos.azure.com/?tls=true&authMechanism=SCRAM-SHA-256&retrywrites=false&maxIdleTimeMS=120000\n",
    "  MONGODB_DATABASE_NAME=MovieVectorDB\n",
    "  MONGODB_COLLECTION_NAME=movies\n",
    "  ```\n",
    "\n",
    "**⚠️ Security Note**: Never commit the `.env` file to version control. Add it to your `.gitignore` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29250410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import ast\n",
    "import warnings\n",
    "from typing import List, Dict, Any\n",
    "import time\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "from pymongo import MongoClient\n",
    "from pymongo.operations import SearchIndexModel\n",
    "from pymongo.errors import OperationFailure, BulkWriteError\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Azure OpenAI Configuration from environment variables\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-06-01\")\n",
    "EMBEDDING_MODEL = os.getenv(\"EMBEDDING_MODEL\", \"text-embedding-ada-002\")\n",
    "GENERATION_MODEL = os.getenv(\"GENERATION_MODEL\", \"gpt-4o\")\n",
    "\n",
    "# MongoDB vCore Configuration from environment variables\n",
    "MONGODB_CONNECTION_STRING = os.getenv(\"MONGODB_CONNECTION_STRING\")\n",
    "MONGODB_DATABASE_NAME = os.getenv(\"MONGODB_DATABASE_NAME\", \"MovieVectorDB\")\n",
    "MONGODB_COLLECTION_NAME = os.getenv(\"MONGODB_COLLECTION_NAME\", \"movies\")\n",
    "\n",
    "# Validate required configuration\n",
    "required_vars = {\n",
    "    \"AZURE_OPENAI_ENDPOINT\": AZURE_OPENAI_ENDPOINT,\n",
    "    \"AZURE_OPENAI_API_KEY\": AZURE_OPENAI_API_KEY,\n",
    "    \"MONGODB_CONNECTION_STRING\": MONGODB_CONNECTION_STRING\n",
    "}\n",
    "missing_vars = [k for k, v in required_vars.items() if not v]\n",
    "if missing_vars:\n",
    "    raise ValueError(f\"Missing required configuration variables: {', '.join(missing_vars)}\")\n",
    "\n",
    "# Initialize Azure OpenAI client\n",
    "openai_client = AzureOpenAI(\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=AZURE_OPENAI_API_VERSION\n",
    ")\n",
    "\n",
    "# Initialize MongoDB client\n",
    "mongo_client = MongoClient(MONGODB_CONNECTION_STRING)\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(f\"Azure OpenAI configured with embedding model: {EMBEDDING_MODEL}\")\n",
    "print(f\"Generation model: {GENERATION_MODEL}\")\n",
    "print(f\"MongoDB configured for database: {MONGODB_DATABASE_NAME}\")\n",
    "print(\"✅ Environment variables loaded from .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083483e0",
   "metadata": {},
   "source": [
    "## 1. Load and Inspect the Movies Dataset\n",
    "\n",
    "Let's start by loading the movies dataset and examining its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c665fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the movies metadata\n",
    "movies_df = pd.read_csv(r'..\\data\\moviesdataset\\movies_metadata.csv', low_memory=False)\n",
    "\n",
    "# Load ratings data (using smaller dataset for demo)\n",
    "ratings_df = pd.read_csv(r'..\\data\\moviesdataset\\ratings_small.csv')\n",
    "\n",
    "print(\"Movies Dataset Shape:\", movies_df.shape)\n",
    "print(\"Ratings Dataset Shape:\", ratings_df.shape)\n",
    "print(\"\\nMovies Dataset Columns:\")\n",
    "print(movies_df.columns.tolist())\n",
    "print(\"\\nFirst few rows of movies dataset:\")\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f81552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and preprocess the data\n",
    "def clean_movies_data(df):\n",
    "    # Remove rows with missing essential data\n",
    "    df_clean = df.dropna(subset=['title', 'overview', 'id']).copy()\n",
    "    \n",
    "    # Convert id to numeric, handling errors\n",
    "    df_clean['id'] = pd.to_numeric(df_clean['id'], errors='coerce')\n",
    "    df_clean = df_clean.dropna(subset=['id'])\n",
    "    df_clean['id'] = df_clean['id'].astype(int)\n",
    "    \n",
    "    # Clean overview text\n",
    "    df_clean['overview'] = df_clean['overview'].str.strip()\n",
    "    df_clean = df_clean[df_clean['overview'].str.len() > 10]  # Remove very short descriptions\n",
    "    \n",
    "    # Parse genres safely\n",
    "    def safe_parse_genres(genres_str):\n",
    "        if pd.isna(genres_str):\n",
    "            return []\n",
    "        try:\n",
    "            genres_list = ast.literal_eval(genres_str)\n",
    "            return [genre['name'] for genre in genres_list] if genres_list else []\n",
    "        except:\n",
    "            return []\n",
    "    \n",
    "    df_clean['genres_list'] = df_clean['genres'].apply(safe_parse_genres)\n",
    "    \n",
    "    # Convert release_date to datetime\n",
    "    df_clean['release_date'] = pd.to_datetime(df_clean['release_date'], errors='coerce')\n",
    "    \n",
    "    # Handle numeric columns\n",
    "    numeric_columns = ['vote_average', 'vote_count', 'popularity', 'runtime']\n",
    "    for col in numeric_columns:\n",
    "        if col in df_clean.columns:\n",
    "            df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Clean the data\n",
    "movies_clean = clean_movies_data(movies_df)\n",
    "print(f\"Original dataset size: {len(movies_df)}\")\n",
    "print(f\"Cleaned dataset size: {len(movies_clean)}\")\n",
    "print(f\"Data reduction: {((len(movies_df) - len(movies_clean)) / len(movies_df) * 100):.1f}%\")\n",
    "\n",
    "# For demo purposes, let's work with a subset\n",
    "SAMPLE_SIZE = 100  # Adjust this based on your needs\n",
    "movies_sample = movies_clean.head(SAMPLE_SIZE).copy()\n",
    "print(f\"\\nUsing sample of {len(movies_sample)} movies for this demo\")\n",
    "movies_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6969ad0",
   "metadata": {},
   "source": [
    "## 2. Set up MongoDB vCore Database and Collection\n",
    "\n",
    "Now let's connect to MongoDB vCore and set up our database and collection for vector operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaeec9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to MongoDB and set up database/collection\n",
    "try:\n",
    "    # Test connection\n",
    "    mongo_client.admin.command('ping')\n",
    "    print(\"✅ Successfully connected to MongoDB vCore\")\n",
    "    \n",
    "    # Get database\n",
    "    database = mongo_client[MONGODB_DATABASE_NAME]\n",
    "    print(f\"✅ Using database: {MONGODB_DATABASE_NAME}\")\n",
    "    \n",
    "    # Get collection\n",
    "    collection = database[MONGODB_COLLECTION_NAME]\n",
    "    print(f\"✅ Using collection: {MONGODB_COLLECTION_NAME}\")\n",
    "    \n",
    "    # Check if collection exists and get document count\n",
    "    doc_count = collection.count_documents({})\n",
    "    print(f\"📊 Current document count: {doc_count}\")\n",
    "    \n",
    "    # Optional: Drop existing collection for fresh start (uncomment if needed)\n",
    "    # collection.drop()\n",
    "    # print(\"🧹 Dropped existing collection for fresh start\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error connecting to MongoDB: {e}\")\n",
    "    raise\n",
    "\n",
    "# List existing indexes\n",
    "try:\n",
    "    indexes = list(collection.list_indexes())\n",
    "    print(f\"\\nExisting indexes:\")\n",
    "    for idx in indexes:\n",
    "        print(f\"  - {idx.get('name', 'unnamed')}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not list indexes: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f93744",
   "metadata": {},
   "source": [
    "## 3. Generate Embeddings with Azure OpenAI\n",
    "\n",
    "We'll create embeddings for movie descriptions using Azure OpenAI's text-embedding-ada-002 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434f7a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get embeddings from Azure OpenAI\n",
    "def get_embedding(text, model=EMBEDDING_MODEL):\n",
    "    \"\"\"Get embedding from Azure OpenAI\"\"\"\n",
    "    try:\n",
    "        response = openai_client.embeddings.create(\n",
    "            input=text,\n",
    "            model=model\n",
    "        )\n",
    "        return response.data[0].embedding\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting embedding for text: {text[:50]}... Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Generate embeddings for our movie sample\n",
    "print(f\"Generating embeddings for {len(movies_sample)} movies...\")\n",
    "successful_embeddings = 0\n",
    "failed_embeddings = 0\n",
    "\n",
    "# Prepare documents for insertion\n",
    "documents_to_insert = []\n",
    "\n",
    "for idx, row in movies_sample.iterrows():\n",
    "    # Create searchable text combining title and overview\n",
    "    search_text = f\"{row['title']} {row['overview']}\"\n",
    "    \n",
    "    # Get embedding\n",
    "    embedding = get_embedding(search_text)\n",
    "    \n",
    "    if embedding is not None:\n",
    "        # Create document for MongoDB\n",
    "        document = {\n",
    "            \"_id\": str(row['id']),  # Use movie ID as document ID\n",
    "            \"movie_id\": int(row['id']),\n",
    "            \"title\": row['title'],\n",
    "            \"overview\": row['overview'],\n",
    "            \"genres\": row['genres_list'],\n",
    "            \"release_date\": row['release_date'].isoformat() if pd.notna(row['release_date']) else None,\n",
    "            \"vote_average\": float(row['vote_average']) if pd.notna(row['vote_average']) else None,\n",
    "            \"vote_count\": int(row['vote_count']) if pd.notna(row['vote_count']) else None,\n",
    "            \"popularity\": float(row['popularity']) if pd.notna(row['popularity']) else None,\n",
    "            \"search_text\": search_text,\n",
    "            \"embedding\": embedding,\n",
    "            \"embedding_model\": EMBEDDING_MODEL,\n",
    "            \"created_at\": datetime.utcnow().isoformat()\n",
    "        }\n",
    "        \n",
    "        documents_to_insert.append(document)\n",
    "        successful_embeddings += 1\n",
    "        \n",
    "        if successful_embeddings % 10 == 0:\n",
    "            print(f\"  Generated {successful_embeddings} embeddings...\")\n",
    "        \n",
    "        # Rate limiting to avoid API throttling\n",
    "        time.sleep(0.1)\n",
    "    else:\n",
    "        failed_embeddings += 1\n",
    "\n",
    "print(f\"\\n✅ Successfully generated {successful_embeddings} embeddings\")\n",
    "print(f\"❌ Failed to generate {failed_embeddings} embeddings\")\n",
    "print(f\"📊 Success rate: {(successful_embeddings / len(movies_sample) * 100):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24873fa5",
   "metadata": {},
   "source": [
    "## 4. Insert Data into MongoDB vCore Collection\n",
    "\n",
    "Now let's insert our movie data with embeddings into the MongoDB collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a096bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert documents into MongoDB collection\n",
    "if documents_to_insert:\n",
    "    try:\n",
    "        print(f\"Inserting {len(documents_to_insert)} documents into MongoDB...\")\n",
    "        \n",
    "        # Use ordered=False for better performance and partial success\n",
    "        result = collection.insert_many(documents_to_insert, ordered=False)\n",
    "        \n",
    "        print(f\"✅ Successfully inserted {len(result.inserted_ids)} documents\")\n",
    "        print(f\"📊 Insertion rate: {(len(result.inserted_ids) / len(documents_to_insert) * 100):.1f}%\")\n",
    "        \n",
    "        # Show sample document structure\n",
    "        sample_doc = collection.find_one()\n",
    "        if sample_doc:\n",
    "            print(f\"\\n📄 Sample document structure:\")\n",
    "            print(f\"  _id: {sample_doc['_id']}\")\n",
    "            print(f\"  title: {sample_doc['title']}\")\n",
    "            print(f\"  genres: {sample_doc['genres']}\")\n",
    "            print(f\"  embedding dimensions: {len(sample_doc['embedding'])}\")\n",
    "            print(f\"  embedding_model: {sample_doc['embedding_model']}\")\n",
    "            \n",
    "    except BulkWriteError as e:\n",
    "        print(f\"⚠️ Partial success during bulk insert:\")\n",
    "        print(f\"  Inserted: {e.details.get('nInserted', 0)} documents\")\n",
    "        print(f\"  Errors: {len(e.details.get('writeErrors', []))}\")\n",
    "        for error in e.details.get('writeErrors', [])[:3]:  # Show first 3 errors\n",
    "            print(f\"    Error: {error.get('errmsg', 'Unknown error')}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during insertion: {e}\")\n",
    "\n",
    "# Get final collection stats\n",
    "final_count = collection.count_documents({})\n",
    "print(f\"\\n📊 Final collection statistics:\")\n",
    "print(f\"  Total documents: {final_count}\")\n",
    "print(f\"  Documents with embeddings: {collection.count_documents({'embedding': {'$exists': True}})}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385f30fc",
   "metadata": {},
   "source": [
    "## 5. Create Vector Search Index\n",
    "\n",
    "MongoDB vCore uses SearchIndexModel to create optimized vector search indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca85f068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector search index\n",
    "vector_index_name = \"vector_index\"\n",
    "\n",
    "# Define vector search index\n",
    "vector_index_model = SearchIndexModel(\n",
    "    definition={\n",
    "        \"fields\": [\n",
    "            {\n",
    "                \"type\": \"vector\",\n",
    "                \"path\": \"embedding\",\n",
    "                \"numDimensions\": 1536,  # text-embedding-ada-002 dimensions\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"filter\",\n",
    "                \"path\": \"genres\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"filter\",\n",
    "                \"path\": \"vote_average\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"filter\",\n",
    "                \"path\": \"release_date\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    name=vector_index_name\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Check if index already exists\n",
    "    existing_indexes = list(collection.list_search_indexes())\n",
    "    index_names = [idx.get('name') for idx in existing_indexes if idx.get('name')]\n",
    "    \n",
    "    if vector_index_name in index_names:\n",
    "        print(f\"✅ Vector search index '{vector_index_name}' already exists\")\n",
    "    else:\n",
    "        print(f\"Creating vector search index '{vector_index_name}'...\")\n",
    "        collection.create_search_index(vector_index_model)\n",
    "        print(f\"✅ Vector search index '{vector_index_name}' created successfully\")\n",
    "        print(\"⏳ Index may take a few minutes to be fully ready for searches\")\n",
    "    \n",
    "    # Wait for index to be ready (optional)\n",
    "    print(\"\\nWaiting 30 seconds for index to initialize...\")\n",
    "    time.sleep(30)\n",
    "    \n",
    "    # List all search indexes\n",
    "    print(\"\\n📋 Current search indexes:\")\n",
    "    search_indexes = list(collection.list_search_indexes())\n",
    "    for idx in search_indexes:\n",
    "        print(f\"  - Name: {idx.get('name')}\")\n",
    "        print(f\"    Status: {idx.get('status', 'unknown')}\")\n",
    "        print(f\"    Type: {idx.get('type', 'unknown')}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Vector index creation: {e}\")\n",
    "    print(\"Note: Some MongoDB vCore instances may require manual index creation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe32d35a",
   "metadata": {},
   "source": [
    "## 6. Semantic Movie Search with Vector Similarity\n",
    "\n",
    "Now let's implement semantic search using MongoDB's $vectorSearch aggregation stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4122a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform semantic movie search\n",
    "def semantic_movie_search(query_text, top_k=5, include_score=True):\n",
    "    \"\"\"\n",
    "    Perform semantic search for movies using MongoDB vector search\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Generate embedding for the query\n",
    "        query_embedding = get_embedding(query_text)\n",
    "        \n",
    "        if query_embedding is None:\n",
    "            return []\n",
    "        \n",
    "        # MongoDB vector search aggregation pipeline\n",
    "        pipeline = [\n",
    "            {\n",
    "                \"$vectorSearch\": {\n",
    "                    \"index\": vector_index_name,\n",
    "                    \"path\": \"embedding\",\n",
    "                    \"queryVector\": query_embedding,\n",
    "                    \"numCandidates\": 100,  # Number of candidates to consider\n",
    "                    \"limit\": top_k\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$project\": {\n",
    "                    \"_id\": 0,\n",
    "                    \"title\": 1,\n",
    "                    \"overview\": 1,\n",
    "                    \"genres\": 1,\n",
    "                    \"vote_average\": 1,\n",
    "                    \"release_date\": 1,\n",
    "                    \"score\": {\"$meta\": \"vectorSearchScore\"} if include_score else None\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Remove null score projection if not needed\n",
    "        if not include_score:\n",
    "            pipeline[1][\"$project\"].pop(\"score\", None)\n",
    "        \n",
    "        # Execute the search\n",
    "        results = list(collection.aggregate(pipeline))\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error performing semantic search: {e}\")\n",
    "        return []\n",
    "\n",
    "# Test semantic search with various queries\n",
    "test_queries = [\n",
    "    \"sci-fi action movie with robots\",\n",
    "    \"romantic comedy about love\",\n",
    "    \"superhero movie with powers\",\n",
    "    \"thriller with mystery and suspense\",\n",
    "    \"animated family-friendly adventure\"\n",
    "]\n",
    "\n",
    "print(\"🔍 Testing Semantic Movie Search\\n\" + \"=\"*50)\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\n🎯 Query: '{query}'\")\n",
    "    print(\"-\" * (len(query) + 10))\n",
    "    \n",
    "    results = semantic_movie_search(query, top_k=3)\n",
    "    \n",
    "    if results:\n",
    "        for i, movie in enumerate(results, 1):\n",
    "            score = movie.get('score', 'N/A')\n",
    "            print(f\"{i}. {movie['title']} (Score: {score:.4f})\")\n",
    "            print(f\"   Genres: {', '.join(movie['genres']) if movie['genres'] else 'N/A'}\")\n",
    "            print(f\"   Rating: {movie.get('vote_average', 'N/A')}/10\")\n",
    "            print(f\"   Overview: {movie['overview'][:100]}...\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"   No results found or search error\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ace52a",
   "metadata": {},
   "source": [
    "## 7. Advanced Filtered Vector Search\n",
    "\n",
    "MongoDB vCore allows combining vector search with traditional filtering for more precise results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f828119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for filtered vector search\n",
    "def filtered_movie_search(query_text, genre_filter=None, min_rating=None, top_k=5):\n",
    "    \"\"\"\n",
    "    Perform semantic search with additional filters\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Generate embedding for the query\n",
    "        query_embedding = get_embedding(query_text)\n",
    "        \n",
    "        if query_embedding is None:\n",
    "            return []\n",
    "        \n",
    "        # Build filter conditions\n",
    "        filter_conditions = {}\n",
    "        \n",
    "        if genre_filter:\n",
    "            filter_conditions[\"genres\"] = {\"$in\": [genre_filter]}\n",
    "        \n",
    "        if min_rating:\n",
    "            filter_conditions[\"vote_average\"] = {\"$gte\": min_rating}\n",
    "        \n",
    "        # MongoDB vector search with filters\n",
    "        pipeline = [\n",
    "            {\n",
    "                \"$vectorSearch\": {\n",
    "                    \"index\": vector_index_name,\n",
    "                    \"path\": \"embedding\",\n",
    "                    \"queryVector\": query_embedding,\n",
    "                    \"numCandidates\": 100,\n",
    "                    \"limit\": top_k,\n",
    "                    \"filter\": filter_conditions if filter_conditions else {}\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$project\": {\n",
    "                    \"_id\": 0,\n",
    "                    \"title\": 1,\n",
    "                    \"overview\": 1,\n",
    "                    \"genres\": 1,\n",
    "                    \"vote_average\": 1,\n",
    "                    \"release_date\": 1,\n",
    "                    \"score\": {\"$meta\": \"vectorSearchScore\"}\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Execute the search\n",
    "        results = list(collection.aggregate(pipeline))\n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error performing filtered search: {e}\")\n",
    "        return []\n",
    "\n",
    "# Test filtered searches\n",
    "print(\"🎯 Testing Filtered Vector Search\\n\" + \"=\"*40)\n",
    "\n",
    "# Search 1: Action movies with good ratings\n",
    "print(\"🔍 Search 1: Action movies with high ratings\")\n",
    "results = filtered_movie_search(\n",
    "    query_text=\"action adventure explosive\", \n",
    "    genre_filter=\"Action\",\n",
    "    min_rating=7.0,\n",
    "    top_k=3\n",
    ")\n",
    "\n",
    "if results:\n",
    "    for i, movie in enumerate(results, 1):\n",
    "        print(f\"{i}. {movie['title']} (Score: {movie['score']:.4f}, Rating: {movie.get('vote_average', 'N/A')})\")\n",
    "        print(f\"   Genres: {', '.join(movie['genres'])}\")\n",
    "        print(f\"   Overview: {movie['overview'][:80]}...\")\n",
    "else:\n",
    "    print(\"   No results found\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "\n",
    "# Search 2: Sci-fi movies\n",
    "print(\"🔍 Search 2: Science Fiction movies\")\n",
    "results = filtered_movie_search(\n",
    "    query_text=\"space future technology\",\n",
    "    genre_filter=\"Science Fiction\",\n",
    "    top_k=3\n",
    ")\n",
    "\n",
    "if results:\n",
    "    for i, movie in enumerate(results, 1):\n",
    "        print(f\"{i}. {movie['title']} (Score: {movie['score']:.4f})\")\n",
    "        print(f\"   Genres: {', '.join(movie['genres'])}\")\n",
    "        print(f\"   Overview: {movie['overview'][:80]}...\")\n",
    "else:\n",
    "    print(\"   No results found\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "\n",
    "# Search 3: High-rated movies regardless of genre\n",
    "print(\"🔍 Search 3: High-rated movies (>8.0)\")\n",
    "results = filtered_movie_search(\n",
    "    query_text=\"great amazing movie\",\n",
    "    min_rating=8.0,\n",
    "    top_k=5\n",
    ")\n",
    "\n",
    "if results:\n",
    "    for i, movie in enumerate(results, 1):\n",
    "        print(f\"{i}. {movie['title']} (Score: {movie['score']:.4f}, Rating: {movie.get('vote_average', 'N/A')})\")\n",
    "        print(f\"   Genres: {', '.join(movie['genres'])}\")\n",
    "else:\n",
    "    print(\"   No high-rated movies found in sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134252b9",
   "metadata": {},
   "source": [
    "## 8. Retrieval-Augmented Generation (RAG) for Movie Recommendations\n",
    "\n",
    "Let's implement a complete RAG pipeline using MongoDB as our vector store and Azure OpenAI for generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cd11af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG Implementation for Movie Recommendations\n",
    "def generate_movie_recommendations_rag(user_query, top_k=5):\n",
    "    \"\"\"\n",
    "    Complete RAG pipeline: Retrieve relevant movies, then generate recommendations\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Step 1: Retrieve relevant movies using semantic search\n",
    "        print(f\"🔍 Searching for movies related to: '{user_query}'\")\n",
    "        relevant_movies = semantic_movie_search(user_query, top_k=top_k, include_score=True)\n",
    "        \n",
    "        if not relevant_movies:\n",
    "            return \"I couldn't find any movies matching your request. Please try a different query.\"\n",
    "        \n",
    "        print(f\"✅ Found {len(relevant_movies)} relevant movies\")\n",
    "        \n",
    "        # Step 2: Prepare context for the LLM\n",
    "        context_movies = []\n",
    "        for movie in relevant_movies:\n",
    "            movie_info = {\n",
    "                \"title\": movie[\"title\"],\n",
    "                \"genres\": \", \".join(movie[\"genres\"]) if movie[\"genres\"] else \"N/A\",\n",
    "                \"rating\": movie.get(\"vote_average\", \"N/A\"),\n",
    "                \"overview\": movie[\"overview\"],\n",
    "                \"relevance_score\": movie.get(\"score\", \"N/A\")\n",
    "            }\n",
    "            context_movies.append(movie_info)\n",
    "        \n",
    "        # Step 3: Create prompt for GPT\n",
    "        context_text = \"\\\\n\\\\n\".join([\n",
    "            f\"Title: {m['title']}\\\\n\"\n",
    "            f\"Genres: {m['genres']}\\\\n\"\n",
    "            f\"Rating: {m['rating']}/10\\\\n\"\n",
    "            f\"Overview: {m['overview']}\\\\n\"\n",
    "            f\"Relevance Score: {m['relevance_score']:.4f}\"\n",
    "            for m in context_movies\n",
    "        ])\n",
    "        \n",
    "        system_prompt = \"\"\"You are a knowledgeable movie recommendation expert. Based on the provided movie information from a vector database search, create personalized and engaging movie recommendations.\n",
    "\n",
    "Guidelines:\n",
    "- Analyze the retrieved movies and their relevance scores\n",
    "- Provide thoughtful recommendations with explanations\n",
    "- Mention genres, ratings, and key themes\n",
    "- Be conversational and engaging\n",
    "- If movies seem unrelated to the query, acknowledge this and try to find connections\"\"\"\n",
    "\n",
    "        user_prompt = f\"\"\"Based on my request: \"{user_query}\"\n",
    "\n",
    "Here are the most relevant movies from our database:\n",
    "\n",
    "{context_text}\n",
    "\n",
    "Please provide detailed movie recommendations based on this information. Explain why these movies match my request and what makes them worth watching.\"\"\"\n",
    "\n",
    "        # Step 4: Generate response using Azure OpenAI\n",
    "        print(\"🤖 Generating personalized recommendations...\")\n",
    "        \n",
    "        completion = openai_client.chat.completions.create(\n",
    "            model=GENERATION_MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=1000\n",
    "        )\n",
    "        \n",
    "        return completion.choices[0].message.content\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in RAG pipeline: {e}\")\n",
    "        return f\"Sorry, I encountered an error while generating recommendations: {str(e)}\"\n",
    "\n",
    "# Test RAG with different user queries\n",
    "test_queries = [\n",
    "    \"I want to watch something exciting with lots of action\",\n",
    "    \"Recommend me a good family movie for weekend\",\n",
    "    \"I'm in the mood for a thought-provoking sci-fi film\",\n",
    "    \"Can you suggest a romantic movie?\",\n",
    "    \"What are some good thriller movies with plot twists?\"\n",
    "]\n",
    "\n",
    "print(\"🎬 Testing RAG Movie Recommendation System\\\\n\" + \"=\"*60)\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\\\n{'='*60}\")\n",
    "    print(f\"Test {i}: {query}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    recommendation = generate_movie_recommendations_rag(query, top_k=3)\n",
    "    print(f\"\\\\n🎯 AI Recommendation:\\\\n{recommendation}\")\n",
    "    \n",
    "    if i < len(test_queries):\n",
    "        print(\"\\\\n\" + \"-\"*40 + \" Next Query \" + \"-\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88727c5",
   "metadata": {},
   "source": [
    "## 9. Performance Analysis and Optimization\n",
    "\n",
    "Let's analyze the performance of our vector operations and explore optimization strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eefcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance benchmarking and analysis\n",
    "import time\n",
    "from statistics import mean, median\n",
    "\n",
    "def benchmark_vector_search(num_tests=5):\n",
    "    \"\"\"\n",
    "    Benchmark vector search performance\n",
    "    \"\"\"\n",
    "    print(\"🚀 Performance Benchmarking\\\\n\" + \"=\"*40)\n",
    "    \n",
    "    test_queries = [\n",
    "        \"action adventure movie\",\n",
    "        \"romantic comedy film\",\n",
    "        \"sci-fi space opera\",\n",
    "        \"thriller mystery movie\",\n",
    "        \"animated family adventure\"\n",
    "    ]\n",
    "    \n",
    "    # Test 1: Simple vector search performance\n",
    "    print(\"📊 Test 1: Simple Vector Search Performance\")\n",
    "    search_times = []\n",
    "    \n",
    "    for i in range(num_tests):\n",
    "        query = test_queries[i % len(test_queries)]\n",
    "        \n",
    "        start_time = time.time()\n",
    "        results = semantic_movie_search(query, top_k=5)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        search_time = (end_time - start_time) * 1000  # Convert to milliseconds\n",
    "        search_times.append(search_time)\n",
    "        \n",
    "        print(f\"  Query {i+1}: {search_time:.2f}ms ({len(results)} results)\")\n",
    "    \n",
    "    print(f\"\\\\n  Average search time: {mean(search_times):.2f}ms\")\n",
    "    print(f\"  Median search time: {median(search_times):.2f}ms\")\n",
    "    print(f\"  Min/Max search time: {min(search_times):.2f}ms / {max(search_times):.2f}ms\")\n",
    "    \n",
    "    # Test 2: Filtered search performance\n",
    "    print(\"\\\\n📊 Test 2: Filtered Vector Search Performance\")\n",
    "    filtered_times = []\n",
    "    \n",
    "    for i in range(num_tests):\n",
    "        query = test_queries[i % len(test_queries)]\n",
    "        \n",
    "        start_time = time.time()\n",
    "        results = filtered_movie_search(query, min_rating=6.0, top_k=5)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        search_time = (end_time - start_time) * 1000\n",
    "        filtered_times.append(search_time)\n",
    "        \n",
    "        print(f\"  Query {i+1}: {search_time:.2f}ms ({len(results)} results)\")\n",
    "    \n",
    "    print(f\"\\\\n  Average filtered search time: {mean(filtered_times):.2f}ms\")\n",
    "    print(f\"  Median filtered search time: {median(filtered_times):.2f}ms\")\n",
    "    \n",
    "    # Test 3: Embedding generation performance\n",
    "    print(\"\\\\n📊 Test 3: Embedding Generation Performance\")\n",
    "    embedding_times = []\n",
    "    \n",
    "    for i in range(3):  # Fewer tests due to API rate limits\n",
    "        query = test_queries[i]\n",
    "        \n",
    "        start_time = time.time()\n",
    "        embedding = get_embedding(query)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        if embedding:\n",
    "            embedding_time = (end_time - start_time) * 1000\n",
    "            embedding_times.append(embedding_time)\n",
    "            print(f\"  Query {i+1}: {embedding_time:.2f}ms\")\n",
    "        \n",
    "        time.sleep(0.1)  # Rate limiting\n",
    "    \n",
    "    if embedding_times:\n",
    "        print(f\"\\\\n  Average embedding time: {mean(embedding_times):.2f}ms\")\n",
    "        print(f\"  Note: Embedding generation includes network latency to Azure OpenAI\")\n",
    "    \n",
    "    return {\n",
    "        \"search_times\": search_times,\n",
    "        \"filtered_times\": filtered_times,\n",
    "        \"embedding_times\": embedding_times\n",
    "    }\n",
    "\n",
    "# Run performance benchmarks\n",
    "benchmark_results = benchmark_vector_search()\n",
    "\n",
    "# Collection statistics\n",
    "print(\"\\\\n📈 Collection Statistics\\\\n\" + \"=\"*30)\n",
    "\n",
    "try:\n",
    "    # Basic collection stats\n",
    "    total_docs = collection.count_documents({})\n",
    "    docs_with_embeddings = collection.count_documents({\"embedding\": {\"$exists\": True}})\n",
    "    \n",
    "    print(f\"Total documents: {total_docs}\")\n",
    "    print(f\"Documents with embeddings: {docs_with_embeddings}\")\n",
    "    print(f\"Embedding coverage: {(docs_with_embeddings/total_docs*100):.1f}%\")\n",
    "    \n",
    "    # Sample document for size analysis\n",
    "    sample_doc = collection.find_one({\"embedding\": {\"$exists\": True}})\n",
    "    if sample_doc:\n",
    "        import sys\n",
    "        doc_size = len(str(sample_doc).encode('utf-8'))\n",
    "        embedding_size = len(str(sample_doc['embedding']).encode('utf-8'))\n",
    "        \n",
    "        print(f\"\\\\nDocument size analysis:\")\n",
    "        print(f\"  Average document size: ~{doc_size} bytes\")\n",
    "        print(f\"  Embedding size: ~{embedding_size} bytes ({embedding_size/doc_size*100:.1f}% of document)\")\n",
    "        print(f\"  Embedding dimensions: {len(sample_doc['embedding'])}\")\n",
    "    \n",
    "    # Index information\n",
    "    print(f\"\\\\nIndex information:\")\n",
    "    indexes = list(collection.list_indexes())\n",
    "    for idx in indexes:\n",
    "        print(f\"  - {idx.get('name', 'unnamed')}: {idx.get('key', {})}\")\n",
    "        \n",
    "    # Search index information\n",
    "    try:\n",
    "        search_indexes = list(collection.list_search_indexes())\n",
    "        print(f\"\\\\nSearch indexes:\")\n",
    "        for idx in search_indexes:\n",
    "            print(f\"  - {idx.get('name')}: {idx.get('status', 'unknown')} status\")\n",
    "    except:\n",
    "        print(\"  Search indexes: Unable to retrieve information\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error getting collection statistics: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227299ac",
   "metadata": {},
   "source": [
    "## 10. Summary and Cleanup\n",
    "\n",
    "Let's summarize what we've accomplished and clean up resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309f1034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo Summary and Cleanup\n",
    "print(\"🎉 MongoDB vCore Vector Database Demo Summary\\\\n\" + \"=\"*50)\n",
    "\n",
    "print(\"✅ What we accomplished:\")\n",
    "print(\"  1. 📊 Loaded and preprocessed the movies dataset\")\n",
    "print(\"  2. 🔌 Connected to Azure Cosmos DB for MongoDB vCore\")\n",
    "print(\"  3. 🧠 Generated embeddings using Azure OpenAI text-embedding-ada-002\")\n",
    "print(\"  4. 💾 Stored movie data with 1536-dimensional embeddings in MongoDB\")\n",
    "print(\"  5. 🔍 Created vector search index using SearchIndexModel\")\n",
    "print(\"  6. 🎯 Implemented semantic search with $vectorSearch aggregation\")\n",
    "print(\"  7. 🎛️ Added filtered search combining vectors with traditional queries\")\n",
    "print(\"  8. 🤖 Built complete RAG pipeline for movie recommendations\")\n",
    "print(\"  9. 📈 Performed performance benchmarking and analysis\")\n",
    "\n",
    "print(\"\\\\n🚀 Key MongoDB vCore Features Demonstrated:\")\n",
    "print(\"  • Native MongoDB vector search with $vectorSearch\")\n",
    "print(\"  • SearchIndexModel for optimized vector indexing\")\n",
    "print(\"  • HNSW/IVF indexing algorithms for high performance\")\n",
    "print(\"  • Seamless integration of vector and document queries\")\n",
    "print(\"  • Rich aggregation pipelines with vector operations\")\n",
    "print(\"  • Familiar MongoDB syntax and ecosystem compatibility\")\n",
    "\n",
    "print(\"\\\\n💡 Production Considerations:\")\n",
    "print(\"  • Index optimization: Choose appropriate numCandidates values\")\n",
    "print(\"  • Batch operations: Use insert_many for bulk vector inserts\")\n",
    "print(\"  • Connection pooling: Reuse MongoDB connections efficiently\")\n",
    "print(\"  • Monitoring: Track vector search performance and index usage\")\n",
    "print(\"  • Scaling: Leverage MongoDB's horizontal sharding capabilities\")\n",
    "print(\"  • Security: Implement proper authentication and network security\")\n",
    "\n",
    "# Collection summary\n",
    "try:\n",
    "    final_stats = {\n",
    "        \"total_documents\": collection.count_documents({}),\n",
    "        \"documents_with_embeddings\": collection.count_documents({\"embedding\": {\"$exists\": True}}),\n",
    "        \"unique_genres\": len(collection.distinct(\"genres\")),\n",
    "        \"avg_rating\": None\n",
    "    }\n",
    "    \n",
    "    # Calculate average rating\n",
    "    rating_pipeline = [\n",
    "        {\"$match\": {\"vote_average\": {\"$exists\": True, \"$ne\": None}}},\n",
    "        {\"$group\": {\"_id\": None, \"avg_rating\": {\"$avg\": \"$vote_average\"}}}\n",
    "    ]\n",
    "    avg_result = list(collection.aggregate(rating_pipeline))\n",
    "    if avg_result:\n",
    "        final_stats[\"avg_rating\"] = avg_result[0][\"avg_rating\"]\n",
    "    \n",
    "    print(f\"\\\\n📊 Final Collection Statistics:\")\n",
    "    print(f\"  Total documents: {final_stats['total_documents']}\")\n",
    "    print(f\"  Documents with embeddings: {final_stats['documents_with_embeddings']}\")\n",
    "    print(f\"  Unique genres represented: {final_stats['unique_genres']}\")\n",
    "    if final_stats[\"avg_rating\"]:\n",
    "        print(f\"  Average movie rating: {final_stats['avg_rating']:.1f}/10\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Could not get final statistics: {e}\")\n",
    "\n",
    "# Optional cleanup (uncomment to remove demo data)\n",
    "print(\"\\\\n🧹 Cleanup Options:\")\n",
    "print(\"  To remove demo data, uncomment and run the following:\")\n",
    "print(\"  # collection.drop()\")\n",
    "print(\"  # print('Demo collection dropped')\")\n",
    "\n",
    "print(\"\\\\n  To remove vector search indexes:\")\n",
    "print(\"  # collection.drop_search_index('vector_index')\")\n",
    "print(\"  # print('Vector search index dropped')\")\n",
    "\n",
    "# Close connections\n",
    "print(\"\\\\n🔐 Closing Connections:\")\n",
    "try:\n",
    "    mongo_client.close()\n",
    "    print(\"✅ MongoDB connection closed\")\n",
    "except Exception as e:\n",
    "    print(f\"Note: {e}\")\n",
    "\n",
    "print(\"\\\\n🎬 Thank you for exploring MongoDB vCore as a vector database!\")\n",
    "print(\"For production deployments, consider:\")\n",
    "print(\"  • Azure Key Vault for credential management\")\n",
    "print(\"  • MongoDB Atlas monitoring and alerting\") \n",
    "print(\"  • Proper indexing strategies for your specific use case\")\n",
    "print(\"  • Load testing with your expected traffic patterns\")\n",
    "print(\"  • Regular backup and disaster recovery procedures\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
